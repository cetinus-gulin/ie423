{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m dfPurchase \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/Colab Notebooks/train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "#dfPurchase = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/train.csv')\n",
    "dfPurchase = pd.read_csv('train.csv')\n",
    "dfPurchase.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select target as a series and features as dataframe\n",
    "y = dfPurchase.loc[:,['Purchase']].values.ravel()\n",
    "X = dfPurchase.drop(['Purchase'],axis=1)\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.8, test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Function for building and scoring Random Forest models\n",
    "def get_random_forest_mae(X_trn, X_tst, y_trn, y_tst):\n",
    "    mdlRfsMlb = RandomForestRegressor(random_state=1)\n",
    "    mdlRfsMlb.fit(X_trn, y_trn)\n",
    "    y_tst_prd = mdlRfsMlb.predict(X_tst)\n",
    "    mae = mean_absolute_error(y_tst, y_tst_prd)\n",
    "    return (mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach 1 - Drop columns with missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric features\n",
    "cols_num = [col for col in X.columns if X[col].dtype in ['int64', 'float64']]\n",
    "Xnum = X[cols_num]\n",
    "\n",
    "# Split numeric features into training and test sets\n",
    "Xnum_train, Xnum_test, y_train, y_test = train_test_split(Xnum,y,train_size=0.8, test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 1 (Drop features with missing values):\n",
      "2091.239815876307\n"
     ]
    }
   ],
   "source": [
    "# Drop empty columns\n",
    "# Identify columns with missing values and then drop such columns\n",
    "cols_num_null = [col for col in Xnum_train.columns\n",
    "    if Xnum_train[col].isnull().any()]\n",
    "Xnum_train_drpnull = Xnum_train.drop(cols_num_null, axis=1)\n",
    "Xnum_test_drpnull = Xnum_test.drop(cols_num_null, axis=1)\n",
    "\n",
    "print('MAE from Approach 1 (Drop features with missing values):')\n",
    "print(get_random_forest_mae(Xnum_train_drpnull, Xnum_test_drpnull, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach 2 - Fill missing values with imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 2 (Replace missing values with forward fill):\n",
      "2272.010880299493\n"
     ]
    }
   ],
   "source": [
    "# Replace with specific value (0, bfill, ffill)\n",
    "Xnum_train_repnull = Xnum_train.fillna(method = 'ffill')\n",
    "Xnum_test_repnull = Xnum_test.fillna(method = 'ffill')\n",
    "\n",
    "print('MAE from Approach 2 (Replace missing values with forward fill):')\n",
    "print(get_random_forest_mae(Xnum_train_repnull, Xnum_test_repnull, y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 2 (Replace missing values with mean):\n",
      "2193.4539755555916\n"
     ]
    }
   ],
   "source": [
    "# Replace with mean value\n",
    "Xnum_train_repnull = Xnum_train.fillna(Xnum_train.mean())\n",
    "Xnum_test_repnull = Xnum_test.fillna(Xnum_train.mean())\n",
    "\n",
    "print('MAE from Approach 2 (Replace missing values with mean):')\n",
    "print(get_random_forest_mae(Xnum_train_repnull, Xnum_test_repnull, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "Dropping features with missing values approach gives us the smallest MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop empty columns\n",
    "# Identify columns with missing values and then drop such columns\n",
    "cols_num_null = [col for col in Xnum_train.columns\n",
    "    if Xnum_train[col].isnull().any()]\n",
    "Xnum_train_drpnull = Xnum_train.drop(cols_num_null, axis=1)\n",
    "Xnum_test_drpnull = Xnum_test.drop(cols_num_null, axis=1)\n",
    "\n",
    "# Going forward, let us remove all missing numeric values\n",
    "X_train[cols_num]=Xnum_train_repnull[cols_num]\n",
    "X_test[cols_num]=Xnum_test_repnull[cols_num]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gender', 'Age', 'City_Category', 'Stay_In_Current_City_Years']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select categorical features\n",
    "cols_cat = [col for col in X.columns if X[col].dtype == 'object' and X[col].nunique()<10]\n",
    "cols_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding on only categorical features\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "Xle_train = X_train.copy()\n",
    "Xle_test = X_test.copy()    \n",
    "# Apply label encoder to each column with categorical data\n",
    "label_encoder = LabelEncoder()\n",
    "for col in cols_cat:\n",
    "    Xle_train[col] = label_encoder.fit_transform(X_train[col])\n",
    "    Xle_test[col] = label_encoder.transform(X_test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Label Encoding all Categorical columns:\n",
      "2154.209866440387\n"
     ]
    }
   ],
   "source": [
    "# Encode and Build/Score using all Categorical columns\n",
    "\n",
    "mae = get_random_forest_mae(Xle_train[cols_num + cols_cat], Xle_test[cols_num + cols_cat], y_train, y_test)\n",
    "print(\"MAE from Label Encoding all Categorical columns:\") \n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Gradient Boosted Tree Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Xle_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Build and score default Gradient Boosting Model\u001b[39;00m\n\u001b[1;32m      4\u001b[0m mdlXgbMlb \u001b[38;5;241m=\u001b[39m XGBRegressor()\n\u001b[0;32m----> 5\u001b[0m mdlXgbMlb\u001b[38;5;241m.\u001b[39mfit(\u001b[43mXle_train\u001b[49m[cols_num \u001b[38;5;241m+\u001b[39m cols_cat], y_train)\n\u001b[1;32m      6\u001b[0m y_test_pred \u001b[38;5;241m=\u001b[39m mdlXgbMlb\u001b[38;5;241m.\u001b[39mpredict(Xle_test[cols_num \u001b[38;5;241m+\u001b[39m cols_cat])\n\u001b[1;32m      7\u001b[0m mae \u001b[38;5;241m=\u001b[39m mean_absolute_error(y_test_pred, y_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Xle_train' is not defined"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "#Build and score default Gradient Boosting Model\n",
    "mdlXgbMlb = XGBRegressor()\n",
    "mdlXgbMlb.fit(Xle_train[cols_num + cols_cat], y_train)\n",
    "y_test_pred = mdlXgbMlb.predict(Xle_test[cols_num + cols_cat])\n",
    "mae = mean_absolute_error(y_test_pred, y_test)\n",
    "\n",
    "print(\"MAE from default XGBoost model:\")\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build and score a tuned Gradient Boosting Model\n",
    "mdlXgbMlb = XGBRegressor(n_estimators=5000, learning_rate=0.01, max_depth=5)\n",
    "mdlXgbMlb.fit(Xle_train[cols_num + cols_cat], y_train)\n",
    "y_test_pred = mdlXgbMlb.predict(Xle_test[cols_num + cols_cat])\n",
    "mae = mean_absolute_error(y_test_pred, y_test)\n",
    "\n",
    "print(\"MAE from tuned XGBoost model:\")\n",
    "print(mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
